{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinct-helena",
   "metadata": {
    "papermill": {
     "duration": 0.010401,
     "end_time": "2021-05-14T23:40:47.910161",
     "exception": false,
     "start_time": "2021-05-14T23:40:47.899760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "understanding-inclusion",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:47.940678Z",
     "iopub.status.busy": "2021-05-14T23:40:47.940046Z",
     "iopub.status.idle": "2021-05-14T23:40:54.929343Z",
     "shell.execute_reply": "2021-05-14T23:40:54.928458Z"
    },
    "papermill": {
     "duration": 7.00994,
     "end_time": "2021-05-14T23:40:54.929506",
     "exception": false,
     "start_time": "2021-05-14T23:40:47.919566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random, os, warnings, math, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from transformers import TFAutoModelForSequenceClassification, TFAutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "seed = 0\n",
    "seed_everything(seed)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-buffer",
   "metadata": {
    "papermill": {
     "duration": 0.009107,
     "end_time": "2021-05-14T23:40:54.948430",
     "exception": false,
     "start_time": "2021-05-14T23:40:54.939323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hardware configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-hunter",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:54.972817Z",
     "iopub.status.busy": "2021-05-14T23:40:54.972276Z",
     "iopub.status.idle": "2021-05-14T23:40:54.979735Z",
     "shell.execute_reply": "2021-05-14T23:40:54.980408Z"
    },
    "papermill": {
     "duration": 0.022786,
     "end_time": "2021-05-14T23:40:54.980531",
     "exception": false,
     "start_time": "2021-05-14T23:40:54.957745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "# TPU or GPU detection\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(f'Running on TPU {tpu.master()}')\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-public",
   "metadata": {
    "papermill": {
     "duration": 0.009478,
     "end_time": "2021-05-14T23:40:54.999891",
     "exception": false,
     "start_time": "2021-05-14T23:40:54.990413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frequent-simpson",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.026257Z",
     "iopub.status.busy": "2021-05-14T23:40:55.025695Z",
     "iopub.status.idle": "2021-05-14T23:40:55.052048Z",
     "shell.execute_reply": "2021-05-14T23:40:55.052452Z"
    },
    "papermill": {
     "duration": 0.042818,
     "end_time": "2021-05-14T23:40:55.052575",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.009757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would keep a bright light burning in the upper story to guide me on my course. On a clear night this light w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every night with the milk. Sometimes Katie went with her, and then they always paused a while under the acorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greeted the eyes of Captain Raymond and his son as they entered the parlor of the adjacent cottage.\\nIt wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolving of defects that prevent correct operation of computer software or a system. Debugging tends to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                    url_legal       license  \\\n",
       "0  c0f722661                                          NaN           NaN   \n",
       "1  f0953f0a5                                          NaN           NaN   \n",
       "2  0df072751                                          NaN           NaN   \n",
       "3  04caf4e0c  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4  0e63f8bea      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "\n",
       "                                                                                                                                                 excerpt  \n",
       "0  My hope lay in Jack's promise that he would keep a bright light burning in the upper story to guide me on my course. On a clear night this light w...  \n",
       "1  Dotty continued to go to Mrs. Gray's every night with the milk. Sometimes Katie went with her, and then they always paused a while under the acorn...  \n",
       "2  It was a bright and cheerful scene that greeted the eyes of Captain Raymond and his son as they entered the parlor of the adjacent cottage.\\nIt wa...  \n",
       "3  Cell division is the process by which a parent cell divides into two or more daughter cells. Cell division usually occurs as part of a larger cell...  \n",
       "4  Debugging is the process of finding and resolving of defects that prevent correct operation of computer software or a system. Debugging tends to b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_filepath = '/kaggle/input/commonlitreadabilityprize/test.csv'\n",
    "test = pd.read_csv(test_filepath)\n",
    "print(f'Test samples: {len(test)}')\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-liquid",
   "metadata": {
    "papermill": {
     "duration": 0.010426,
     "end_time": "2021-05-14T23:40:55.073723",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.063297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-security",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.099703Z",
     "iopub.status.busy": "2021-05-14T23:40:55.099046Z",
     "iopub.status.idle": "2021-05-14T23:40:55.101841Z",
     "shell.execute_reply": "2021-05-14T23:40:55.101460Z"
    },
    "papermill": {
     "duration": 0.017274,
     "end_time": "2021-05-14T23:40:55.101951",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.084677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 * REPLICAS\n",
    "SEQ_LEN = 256\n",
    "BASE_MODEL = '/kaggle/input/huggingface-roberta/roberta-large/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-jones",
   "metadata": {
    "papermill": {
     "duration": 0.010665,
     "end_time": "2021-05-14T23:40:55.123234",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.112569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helpful-broad",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.155042Z",
     "iopub.status.busy": "2021-05-14T23:40:55.154288Z",
     "iopub.status.idle": "2021-05-14T23:40:55.156549Z",
     "shell.execute_reply": "2021-05-14T23:40:55.156937Z"
    },
    "papermill": {
     "duration": 0.022794,
     "end_time": "2021-05-14T23:40:55.157072",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.134278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets utility functions\n",
    "def custom_standardization(text):\n",
    "    text = text.lower() # if encoder is uncased\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def sample_target(features, target):\n",
    "    mean, stddev = target\n",
    "    sampled_target = tf.random.normal([], mean=tf.cast(mean, dtype=tf.float32), \n",
    "                                      stddev=tf.cast(stddev, dtype=tf.float32), dtype=tf.float32)\n",
    "    \n",
    "    return (features, sampled_target)\n",
    "    \n",
    "\n",
    "def get_dataset(pandas_df, tokenizer, labeled=True, ordered=False, repeated=False, \n",
    "                is_sampled=False, batch_size=32, seq_len=128):\n",
    "    \"\"\"\n",
    "        Return a Tensorflow dataset ready for training or inference.\n",
    "    \"\"\"\n",
    "    text = [custom_standardization(text) for text in pandas_df['excerpt']]\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    tokenized_inputs = tokenizer(text, max_length=seq_len, truncation=True, \n",
    "                                 padding='max_length', return_tensors='tf')\n",
    "    \n",
    "    if labeled:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': tokenized_inputs['input_ids'], \n",
    "                                                      'attention_mask': tokenized_inputs['attention_mask']}, \n",
    "                                                      (pandas_df['target'], pandas_df['standard_error'])))\n",
    "        if is_sampled:\n",
    "            dataset = dataset.map(sample_target, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices({'input_ids': tokenized_inputs['input_ids'], \n",
    "                                                      'attention_mask': tokenized_inputs['attention_mask']})\n",
    "        \n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "visible-chicago",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.182554Z",
     "iopub.status.busy": "2021-05-14T23:40:55.182027Z",
     "iopub.status.idle": "2021-05-14T23:40:55.821540Z",
     "shell.execute_reply": "2021-05-14T23:40:55.821049Z"
    },
    "papermill": {
     "duration": 0.653793,
     "end_time": "2021-05-14T23:40:55.821660",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.167867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-commonlit-roberta-large-seq-256  huggingface-bert\r\n",
      "commonlitreadabilityprize\t   huggingface-roberta\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demonstrated-roller",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.848864Z",
     "iopub.status.busy": "2021-05-14T23:40:55.848382Z",
     "iopub.status.idle": "2021-05-14T23:40:55.860280Z",
     "shell.execute_reply": "2021-05-14T23:40:55.860642Z"
    },
    "papermill": {
     "duration": 0.027041,
     "end_time": "2021-05-14T23:40:55.860763",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.833722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to predict:\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_0.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_1.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_2.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_3.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_4.h5\n"
     ]
    }
   ],
   "source": [
    "model_path_list = glob.glob('/kaggle/input/3-commonlit-roberta-large-seq-256/*.h5')\n",
    "model_path_list.sort()\n",
    "\n",
    "print('Models to predict:')\n",
    "print(*model_path_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-classroom",
   "metadata": {
    "papermill": {
     "duration": 0.011349,
     "end_time": "2021-05-14T23:40:55.883734",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.872385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "danish-accordance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T23:40:55.913526Z",
     "iopub.status.busy": "2021-05-14T23:40:55.913038Z",
     "iopub.status.idle": "2021-05-14T23:41:23.901220Z",
     "shell.execute_reply": "2021-05-14T23:41:23.900762Z"
    },
    "papermill": {
     "duration": 28.00602,
     "end_time": "2021-05-14T23:41:23.901350",
     "exception": false,
     "start_time": "2021-05-14T23:40:55.895330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /kaggle/input/huggingface-roberta/roberta-large/ were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /kaggle/input/huggingface-roberta/roberta-large/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 355359744   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 1024)         0           tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            1025        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 355,360,769\n",
      "Trainable params: 355,360,769\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_fn(encoder, seq_len=256):\n",
    "    input_ids = L.Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n",
    "    input_attention_mask = L.Input(shape=(seq_len,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    outputs = encoder({'input_ids': input_ids, \n",
    "                       'attention_mask': input_attention_mask})\n",
    "    last_hidden_state = outputs['last_hidden_state']\n",
    "    \n",
    "    x = L.GlobalAveragePooling1D()(last_hidden_state)\n",
    "    output = L.Dense(1, name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, input_attention_mask], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    encoder = TFAutoModel.from_pretrained(BASE_MODEL)\n",
    "    model = model_fn(encoder, SEQ_LEN)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-tower",
   "metadata": {
    "papermill": {
     "duration": 0.01246,
     "end_time": "2021-05-14T23:41:23.927044",
     "exception": false,
     "start_time": "2021-05-14T23:41:23.914584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "committed-tract",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-14T23:41:23.958050Z",
     "iopub.status.busy": "2021-05-14T23:41:23.957510Z",
     "iopub.status.idle": "2021-05-14T23:42:26.198144Z",
     "shell.execute_reply": "2021-05-14T23:42:26.197669Z"
    },
    "papermill": {
     "duration": 62.258463,
     "end_time": "2021-05-14T23:42:26.198279",
     "exception": false,
     "start_time": "2021-05-14T23:41:23.939816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_0.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_1.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_2.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_3.h5\n",
      "/kaggle/input/3-commonlit-roberta-large-seq-256/model_4.h5\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "test_pred = []\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(model_path)\n",
    "    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    K.clear_session()\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # Test predictions\n",
    "    test_ds = get_dataset(test, tokenizer, labeled=False, ordered=True, batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n",
    "    x_test = test_ds.map(lambda sample: sample)\n",
    "    test_pred.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-seventh",
   "metadata": {
    "papermill": {
     "duration": 0.013875,
     "end_time": "2021-05-14T23:42:26.226330",
     "exception": false,
     "start_time": "2021-05-14T23:42:26.212455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addressed-inside",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T23:42:26.265577Z",
     "iopub.status.busy": "2021-05-14T23:42:26.265074Z",
     "iopub.status.idle": "2021-05-14T23:42:26.418845Z",
     "shell.execute_reply": "2021-05-14T23:42:26.417959Z"
    },
    "papermill": {
     "duration": 0.178864,
     "end_time": "2021-05-14T23:42:26.418996",
     "exception": false,
     "start_time": "2021-05-14T23:42:26.240132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.563160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.401880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.520764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-1.722423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.533928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.169160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>-0.210983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.563160\n",
       "1  f0953f0a5 -0.401880\n",
       "2  0df072751 -0.520764\n",
       "3  04caf4e0c -1.722423\n",
       "4  0e63f8bea -1.533928\n",
       "5  12537fe78 -1.169160\n",
       "6  965e592c0 -0.210983"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = test[['id']]\n",
    "submission['target'] = np.mean(test_pred, axis=0)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "display(submission.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.68262,
   "end_time": "2021-05-14T23:42:28.999924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-14T23:40:41.317304",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
